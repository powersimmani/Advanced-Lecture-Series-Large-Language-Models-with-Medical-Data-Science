<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mamba: State Space Models with Linear Complexity</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Aptos, 'Segoe UI', sans-serif;
            background: white;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }
        
        .container {
            width: 960px;
            height: 540px;
            padding: 35px 45px;
            background: white;
        }
        
        .title {
            font-size: 20px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 25px;
            text-align: center;
        }
        
        .content-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 20px;
            margin-bottom: 20px;
        }
        
        .content-card {
            background: white;
            border: 2.5px solid #1E64C8;
            border-radius: 10px;
            padding: 20px;
            transition: all 0.3s;
        }
        
        .content-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 6px 20px rgba(30, 100, 200, 0.2);
            background: #f8fbff;
        }
        
        .card-title {
            font-size: 17px;
            font-weight: 700;
            color: #1E64C8;
            margin-bottom: 12px;
        }
        
        .card-text {
            font-size: 15px;
            color: #333;
            line-height: 1.5;
            margin-bottom: 8px;
        }
        
        .highlight-box {
            background: #f0f5fc;
            border: 2px solid #1E64C8;
            border-radius: 8px;
            padding: 15px 20px;
            margin-top: 20px;
        }
        
        .highlight-title {
            font-size: 16px;
            font-weight: 700;
            color: #1E64C8;
            margin-bottom: 8px;
            text-align: center;
        }
        
        .highlight-text {
            font-size: 15px;
            color: #333;
            text-align: center;
            line-height: 1.5;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="title">Mamba: State Space Models with Linear Complexity</div>
        <div class="content-grid">
            <div class="content-card">
                <div class="card-title">State Space Models</div>
                <div class="card-text">• Continuous-time dynamics</div>
                <div class="card-text">• Linear recurrence formulation</div>
                <div class="card-text">• Efficient long sequences</div>
            </div>
            <div class="content-card">
                <div class="card-title">Mamba Architecture</div>
                <div class="card-text">• Selective state spaces</div>
                <div class="card-text">• Input-dependent transitions</div>
                <div class="card-text">• O(n) time and memory</div>
            </div>
            <div class="content-card">
                <div class="card-title">Advantages over Transformers</div>
                <div class="card-text">• Linear scaling with sequence length</div>
                <div class="card-text">• Better for very long contexts (1M+)</div>
                <div class="card-text">• Faster inference</div>
            </div>
            <div class="content-card">
                <div class="card-title">Medical Applications</div>
                <div class="card-text">• ICU time-series monitoring</div>
                <div class="card-text">• Continuous glucose tracking</div>
                <div class="card-text">• Long-term EEG analysis</div>
            </div>
        </div>
        <div class="highlight-box">
            <div class="highlight-title">⚡ Next-Gen Efficiency</div>
            <div class="highlight-text">Mamba achieves Transformer-level performance with O(n) complexity instead of O(n²), enabling processing of million-token medical time-series in real-time.</div>
        </div>
    </div>
</body>
</html>