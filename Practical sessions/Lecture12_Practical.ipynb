{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Model Compression Practice: From Theory to Implementation\n",
    "\n",
    "## Table of Contents\n",
    "1. [Knowledge Distillation](#practice-1-knowledge-distillation)\n",
    "2. [Temperature Scaling](#practice-2-temperature-scaling)\n",
    "3. [INT8 Quantization](#practice-3-int8-quantization)\n",
    "4. [Magnitude Pruning](#practice-4-magnitude-pruning)\n",
    "5. [Complete Pipeline: Compress a Medical Image Classifier](#practice-5-complete-pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Knowledge Distillation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the Teacher-Student framework\n",
    "- Implement soft target training\n",
    "- Learn how knowledge transfers from large to small models\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Knowledge Distillation:** Transfer knowledge from a large \"Teacher\" model to a smaller \"Student\" model\n",
    "- **Teacher Model:** Large, accurate model (pre-trained)\n",
    "- **Student Model:** Small, efficient model (to be trained)\n",
    "- **Soft Targets:** Probability distributions from teacher (richer than hard labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Prepare a simple dataset (CIFAR-10 subset for speed)\n",
    "def prepare_data(num_samples=1000):\n",
    "    \"\"\"Prepare a small CIFAR-10 dataset for quick practice\"\"\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Load CIFAR-10\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    # Use subset for quick training\n",
    "    train_subset = torch.utils.data.Subset(trainset, range(num_samples))\n",
    "    test_subset = torch.utils.data.Subset(testset, range(num_samples // 5))\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    print(f\"‚úÖ Training samples: {len(train_subset)}\")\n",
    "    print(f\"‚úÖ Test samples: {len(test_subset)}\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Define Teacher and Student models\n",
    "class TeacherModel(nn.Module):\n",
    "    \"\"\"Large teacher model (ResNet-like)\"\"\"\n",
    "    def __init__(self):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    \"\"\"Small student model (MobileNet-like)\"\"\"\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create models and show size comparison\n",
    "teacher = TeacherModel().to(device)\n",
    "student = StudentModel().to(device)\n",
    "\n",
    "teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "student_params = sum(p.numel() for p in student.parameters())\n",
    "\n",
    "print(f\"\\nüìä Model Size Comparison:\")\n",
    "print(f\"Teacher model: {teacher_params:,} parameters\")\n",
    "print(f\"Student model: {student_params:,} parameters\")\n",
    "print(f\"Compression ratio: {teacher_params / student_params:.1f}x smaller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Temperature Scaling\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand temperature parameter T in softmax\n",
    "- Visualize how temperature affects probability distributions\n",
    "- Implement distillation loss with temperature\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Temperature Scaling:** $p_i = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$\n",
    "- **T = 1:** Normal softmax (sharp distribution)\n",
    "- **T = 3~5:** Optimal for distillation (soft distribution)\n",
    "- **T ‚Üí ‚àû:** Uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Visualize temperature effects\n",
    "def visualize_temperature_effect():\n",
    "    \"\"\"Show how temperature affects softmax output\"\"\"\n",
    "    \n",
    "    # Sample logits\n",
    "    logits = torch.tensor([2.0, 1.0, 0.5, 0.1])\n",
    "    temperatures = [1, 3, 5, 10]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    for idx, T in enumerate(temperatures):\n",
    "        # Apply temperature scaling\n",
    "        scaled_logits = logits / T\n",
    "        probs = F.softmax(scaled_logits, dim=0).numpy()\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx].bar(range(4), probs, color=['#1E64C8', '#51cf66', '#ffa500', '#ff6b6b'])\n",
    "        axes[idx].set_title(f'T = {T}', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_ylim([0, 1])\n",
    "        axes[idx].set_ylabel('Probability')\n",
    "        axes[idx].set_xlabel('Class')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, v in enumerate(probs):\n",
    "            axes[idx].text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/mnt/user-data/outputs/temperature_effect.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Observation:\")\n",
    "    print(\"  ‚Ä¢ T=1: Sharp distribution (one class dominates)\")\n",
    "    print(\"  ‚Ä¢ T=3~5: Softer distribution (preserves class relationships)\")\n",
    "    print(\"  ‚Ä¢ T=10: Nearly uniform (loses discriminative information)\")\n",
    "\n",
    "visualize_temperature_effect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Implement distillation loss\n",
    "def distillation_loss(student_logits, teacher_logits, labels, T=3, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Calculate distillation loss combining soft and hard targets\n",
    "    \n",
    "    Args:\n",
    "        student_logits: Student model outputs\n",
    "        teacher_logits: Teacher model outputs\n",
    "        labels: True labels\n",
    "        T: Temperature for softening distributions\n",
    "        alpha: Weight for soft loss (1-alpha for hard loss)\n",
    "    \"\"\"\n",
    "    # Soft targets loss (KL divergence with temperature)\n",
    "    soft_targets = F.softmax(teacher_logits / T, dim=1)\n",
    "    soft_student = F.log_softmax(student_logits / T, dim=1)\n",
    "    soft_loss = F.kl_div(soft_student, soft_targets, reduction='batchmean') * (T * T)\n",
    "    \n",
    "    # Hard targets loss (standard cross-entropy)\n",
    "    hard_loss = F.cross_entropy(student_logits, labels)\n",
    "    \n",
    "    # Combined loss\n",
    "    total_loss = alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "    \n",
    "    return total_loss, soft_loss, hard_loss\n",
    "\n",
    "# Test the loss function\n",
    "dummy_student = torch.randn(4, 10)\n",
    "dummy_teacher = torch.randn(4, 10)\n",
    "dummy_labels = torch.tensor([1, 3, 5, 7])\n",
    "\n",
    "total, soft, hard = distillation_loss(dummy_student, dummy_teacher, dummy_labels)\n",
    "print(f\"\\nüìä Distillation Loss Components:\")\n",
    "print(f\"  Soft loss (from teacher): {soft.item():.4f}\")\n",
    "print(f\"  Hard loss (from labels): {hard.item():.4f}\")\n",
    "print(f\"  Total loss: {total.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: INT8 Quantization\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand quantization from FP32 to INT8\n",
    "- Implement post-training quantization\n",
    "- Measure model size reduction\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Quantization:** Convert floating-point to integers\n",
    "- **FP32:** 32 bits (4 bytes) - Default training precision\n",
    "- **INT8:** 8 bits (1 byte) - 75% memory reduction\n",
    "- **Benefits:** Faster inference, lower memory, better battery life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Implement simple quantization\n",
    "def quantize_model_simple(model):\n",
    "    \"\"\"\n",
    "    Apply PyTorch dynamic quantization\n",
    "    (Simple post-training quantization without calibration)\n",
    "    \"\"\"\n",
    "    # Create a copy\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model,\n",
    "        {nn.Linear, nn.Conv2d},  # Layers to quantize\n",
    "        dtype=torch.qint8\n",
    "    )\n",
    "    \n",
    "    return quantized_model\n",
    "\n",
    "# Apply quantization to student model\n",
    "student_fp32 = StudentModel().to('cpu')  # Quantization requires CPU\n",
    "student_int8 = quantize_model_simple(student_fp32)\n",
    "\n",
    "# Compare sizes\n",
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in MB\"\"\"\n",
    "    torch.save(model.state_dict(), \"/tmp/temp_model.pth\")\n",
    "    size_mb = os.path.getsize(\"/tmp/temp_model.pth\") / (1024 * 1024)\n",
    "    return size_mb\n",
    "\n",
    "import os\n",
    "size_fp32 = get_model_size(student_fp32)\n",
    "size_int8 = get_model_size(student_int8)\n",
    "\n",
    "print(f\"\\nüìä Quantization Results:\")\n",
    "print(f\"  FP32 model size: {size_fp32:.2f} MB\")\n",
    "print(f\"  INT8 model size: {size_int8:.2f} MB\")\n",
    "print(f\"  Size reduction: {(1 - size_int8/size_fp32)*100:.1f}%\")\n",
    "print(f\"  Compression ratio: {size_fp32/size_int8:.1f}x smaller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Visualize weight distributions before and after quantization\n",
    "def visualize_quantization():\n",
    "    \"\"\"Compare weight distributions\"\"\"\n",
    "    \n",
    "    # Get weights from first conv layer\n",
    "    fp32_weights = student_fp32.conv1.weight.data.flatten().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # FP32 distribution\n",
    "    axes[0].hist(fp32_weights, bins=50, color='#1E64C8', alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_title('FP32 Weights Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Weight Value')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Simulated INT8 (quantized to 256 levels)\n",
    "    min_val, max_val = fp32_weights.min(), fp32_weights.max()\n",
    "    scale = (max_val - min_val) / 255\n",
    "    int8_weights = np.round((fp32_weights - min_val) / scale)\n",
    "    int8_weights = int8_weights * scale + min_val\n",
    "    \n",
    "    axes[1].hist(int8_weights, bins=50, color='#51cf66', alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_title('INT8 Weights Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Weight Value')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/mnt/user-data/outputs/quantization_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Weight Statistics:\")\n",
    "    print(f\"  FP32 - Min: {fp32_weights.min():.6f}, Max: {fp32_weights.max():.6f}\")\n",
    "    print(f\"  INT8 - Unique values: {len(np.unique(int8_weights))} (vs 256 possible levels)\")\n",
    "\n",
    "visualize_quantization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Magnitude Pruning\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand magnitude-based pruning\n",
    "- Implement weight pruning with different sparsity levels\n",
    "- Visualize sparsity patterns\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Magnitude Pruning:** Remove weights with small absolute values\n",
    "- Set small weights to zero ‚Üí sparse network\n",
    "- **Sparsity:** Percentage of zero weights (e.g., 50% = half weights are zero)\n",
    "- **Threshold:** Weights below threshold ‚Üí 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Implement magnitude pruning\n",
    "def magnitude_pruning(model, sparsity=0.5):\n",
    "    \"\"\"\n",
    "    Apply magnitude-based pruning to all Conv2d and Linear layers\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        sparsity: Fraction of weights to prune (0 to 1)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüî™ Applying {sparsity*100:.0f}% magnitude pruning...\\n\")\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Get weights\n",
    "            weights = module.weight.data\n",
    "            \n",
    "            # Calculate threshold\n",
    "            threshold = torch.quantile(torch.abs(weights), sparsity)\n",
    "            \n",
    "            # Create mask\n",
    "            mask = torch.abs(weights) > threshold\n",
    "            \n",
    "            # Apply mask\n",
    "            weights *= mask.float()\n",
    "            \n",
    "            # Statistics\n",
    "            total_params = weights.numel()\n",
    "            zero_params = (weights == 0).sum().item()\n",
    "            actual_sparsity = zero_params / total_params\n",
    "            \n",
    "            print(f\"  {name:20s} | Sparsity: {actual_sparsity*100:5.1f}% | \"\n",
    "                  f\"Params: {total_params:7,} | Zeros: {zero_params:7,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test pruning\n",
    "student_pruned = StudentModel()\n",
    "student_pruned = magnitude_pruning(student_pruned, sparsity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Visualize pruning effect on different sparsity levels\n",
    "def compare_sparsity_levels():\n",
    "    \"\"\"Compare different pruning levels\"\"\"\n",
    "    \n",
    "    sparsity_levels = [0.0, 0.3, 0.5, 0.7, 0.9]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    \n",
    "    for idx, sparsity in enumerate(sparsity_levels):\n",
    "        # Create fresh model and prune\n",
    "        model = StudentModel()\n",
    "        if sparsity > 0:\n",
    "            model = magnitude_pruning(model, sparsity=sparsity)\n",
    "        \n",
    "        # Get first conv layer weights\n",
    "        weights = model.conv1.weight.data[0, 0].numpy()  # First filter, first channel\n",
    "        \n",
    "        # Plot\n",
    "        im = axes[idx].imshow(weights, cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n",
    "        axes[idx].set_title(f'Sparsity: {sparsity*100:.0f}%', fontsize=12, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Count zeros\n",
    "        zeros = (weights == 0).sum()\n",
    "        total = weights.size\n",
    "        axes[idx].text(0.5, -0.1, f'{zeros}/{total} zeros', \n",
    "                      ha='center', transform=axes[idx].transAxes, fontsize=10)\n",
    "    \n",
    "    plt.colorbar(im, ax=axes, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/mnt/user-data/outputs/pruning_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Observation:\")\n",
    "    print(\"  ‚Ä¢ White pixels = zero weights (pruned)\")\n",
    "    print(\"  ‚Ä¢ Colored pixels = remaining weights\")\n",
    "    print(\"  ‚Ä¢ Higher sparsity = more white (more compression, potential accuracy loss)\")\n",
    "\n",
    "compare_sparsity_levels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Complete Pipeline - Compress a Medical Image Classifier\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Combine distillation + quantization + pruning\n",
    "- Train a complete compressed model\n",
    "- Evaluate the compression-accuracy tradeoff\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Complete Compression Pipeline:**\n",
    "1. Train large teacher model (or use pre-trained)\n",
    "2. Distill to smaller student\n",
    "3. Apply pruning\n",
    "4. Apply quantization\n",
    "5. Measure final model size and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Quick training function\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device, use_distillation=False, teacher=None, T=3):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    if teacher is not None:\n",
    "        teacher.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if use_distillation and teacher is not None:\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "            loss, _, _ = distillation_loss(outputs, teacher_outputs, labels, T=T)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"Evaluate model accuracy\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Complete compression pipeline\n",
    "def complete_compression_pipeline():\n",
    "    \"\"\"Run the full model compression pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"üöÄ COMPLETE MODEL COMPRESSION PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 1: Train baseline teacher\n",
    "    print(\"\\nüìö Step 1: Training Teacher Model (3 epochs)...\")\n",
    "    teacher = TeacherModel().to(device)\n",
    "    optimizer = torch.optim.Adam(teacher.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        loss, acc = train_one_epoch(teacher, train_loader, optimizer, criterion, device)\n",
    "        print(f\"  Epoch {epoch+1}/3 - Loss: {loss:.4f}, Acc: {acc:.2f}%\")\n",
    "    \n",
    "    teacher_acc = evaluate(teacher, test_loader, device)\n",
    "    teacher_size = sum(p.numel() for p in teacher.parameters())\n",
    "    results['teacher'] = {'accuracy': teacher_acc, 'params': teacher_size}\n",
    "    print(f\"  ‚úÖ Teacher - Accuracy: {teacher_acc:.2f}%, Params: {teacher_size:,}\")\n",
    "    \n",
    "    # Step 2: Train student with distillation\n",
    "    print(\"\\nüéì Step 2: Training Student with Distillation (3 epochs)...\")\n",
    "    student = StudentModel().to(device)\n",
    "    optimizer = torch.optim.Adam(student.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        loss, acc = train_one_epoch(student, train_loader, optimizer, criterion, device,\n",
    "                                    use_distillation=True, teacher=teacher, T=3)\n",
    "        print(f\"  Epoch {epoch+1}/3 - Loss: {loss:.4f}, Acc: {acc:.2f}%\")\n",
    "    \n",
    "    student_acc = evaluate(student, test_loader, device)\n",
    "    student_size = sum(p.numel() for p in student.parameters())\n",
    "    results['student'] = {'accuracy': student_acc, 'params': student_size}\n",
    "    print(f\"  ‚úÖ Student - Accuracy: {student_acc:.2f}%, Params: {student_size:,}\")\n",
    "    \n",
    "    # Step 3: Apply pruning\n",
    "    print(\"\\nüî™ Step 3: Applying 50% Magnitude Pruning...\")\n",
    "    student_pruned = magnitude_pruning(student, sparsity=0.5)\n",
    "    pruned_acc = evaluate(student_pruned, test_loader, device)\n",
    "    pruned_size = sum((p != 0).sum().item() for p in student_pruned.parameters())\n",
    "    results['pruned'] = {'accuracy': pruned_acc, 'params': pruned_size}\n",
    "    print(f\"  ‚úÖ Pruned - Accuracy: {pruned_acc:.2f}%, Non-zero params: {pruned_size:,}\")\n",
    "    \n",
    "    # Step 4: Apply quantization\n",
    "    print(\"\\n‚öôÔ∏è  Step 4: Applying INT8 Quantization...\")\n",
    "    student_pruned_cpu = student_pruned.to('cpu')\n",
    "    student_quantized = quantize_model_simple(student_pruned_cpu)\n",
    "    \n",
    "    # Evaluate quantized model (on CPU)\n",
    "    test_loader_cpu = DataLoader(\n",
    "        torch.utils.data.Subset(datasets.CIFAR10(root='./data', train=False, download=True, \n",
    "                                                 transform=transforms.Compose([\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                                 ])), range(200)),\n",
    "        batch_size=64, shuffle=False)\n",
    "    \n",
    "    quantized_acc = evaluate(student_quantized, test_loader_cpu, 'cpu')\n",
    "    results['quantized'] = {'accuracy': quantized_acc, 'params': pruned_size}  # Same params, but INT8\n",
    "    print(f\"  ‚úÖ Quantized - Accuracy: {quantized_acc:.2f}%, Params: {pruned_size:,} (INT8)\")\n",
    "    \n",
    "    return results, teacher, student, student_pruned, student_quantized\n",
    "\n",
    "# Run the pipeline\n",
    "results, teacher_final, student_final, pruned_final, quantized_final = complete_compression_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Visualize final results\n",
    "def visualize_compression_results(results):\n",
    "    \"\"\"Create comprehensive visualization of compression results\"\"\"\n",
    "    \n",
    "    models = ['Teacher', 'Student\\n(Distilled)', 'Pruned\\n(50%)', 'Quantized\\n(INT8)']\n",
    "    accuracies = [results['teacher']['accuracy'], results['student']['accuracy'],\n",
    "                 results['pruned']['accuracy'], results['quantized']['accuracy']]\n",
    "    params = [results['teacher']['params'], results['student']['params'],\n",
    "             results['pruned']['params'], results['quantized']['params']]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    colors = ['#ff6b6b', '#ffa500', '#51cf66', '#1E64C8']\n",
    "    bars1 = axes[0].bar(models, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    axes[0].set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylim([0, 100])\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, acc in zip(bars1, accuracies):\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acc:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Parameter count comparison (log scale)\n",
    "    bars2 = axes[1].bar(models, params, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    axes[1].set_ylabel('Parameters (count)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Model Size Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, param in zip(bars2, params):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{param:,}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/mnt/user-data/outputs/compression_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä FINAL COMPRESSION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Model':<20} {'Accuracy':<15} {'Parameters':<15} {'Compression Ratio':<20}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    baseline = results['teacher']['params']\n",
    "    for name, key in zip(models, ['teacher', 'student', 'pruned', 'quantized']):\n",
    "        acc = results[key]['accuracy']\n",
    "        param = results[key]['params']\n",
    "        ratio = baseline / param\n",
    "        name_clean = name.replace('\\n', ' ')\n",
    "        print(f\"{name_clean:<20} {acc:>6.2f}%        {param:>10,}      {ratio:>6.1f}x smaller\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc_drop = results['teacher']['accuracy'] - results['quantized']['accuracy']\n",
    "    size_reduction = (1 - results['quantized']['params'] / results['teacher']['params']) * 100\n",
    "    \n",
    "    print(f\"\\nüéØ Key Metrics:\")\n",
    "    print(f\"  ‚Ä¢ Accuracy drop: {acc_drop:.2f}%\")\n",
    "    print(f\"  ‚Ä¢ Size reduction: {size_reduction:.1f}%\")\n",
    "    print(f\"  ‚Ä¢ Final compression ratio: {baseline / results['quantized']['params']:.1f}x\")\n",
    "    print(f\"\\n‚úÖ Successfully compressed the model with minimal accuracy loss!\")\n",
    "\n",
    "visualize_compression_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **Knowledge Distillation**: Transferring knowledge from teacher to student\n",
    "   - Teacher-Student framework\n",
    "   - Soft targets with temperature scaling\n",
    "   \n",
    "2. **Temperature Scaling**: Controlling the \"softness\" of probability distributions\n",
    "   - T = 1: Sharp (standard softmax)\n",
    "   - T = 3~5: Optimal for distillation\n",
    "   - T ‚Üí ‚àû: Uniform\n",
    "\n",
    "3. **INT8 Quantization**: Converting FP32 ‚Üí INT8\n",
    "   - 75% memory reduction\n",
    "   - Minimal accuracy loss\n",
    "   - Faster inference\n",
    "\n",
    "4. **Magnitude Pruning**: Removing small weights\n",
    "   - Setting weights to zero based on magnitude\n",
    "   - Creating sparse networks\n",
    "   - Balancing sparsity and accuracy\n",
    "\n",
    "5. **Complete Pipeline**: Combining all techniques\n",
    "   - Distillation ‚Üí Pruning ‚Üí Quantization\n",
    "   - Achieving 10-100x compression\n",
    "   - Minimal accuracy degradation\n",
    "\n",
    "### Key Insights:\n",
    "- Model compression is essential for deploying AI on edge devices\n",
    "- Different techniques address different aspects (knowledge, precision, sparsity)\n",
    "- Combining techniques leads to the best results\n",
    "- Always measure the accuracy-size tradeoff\n",
    "\n",
    "### Real-World Applications:\n",
    "- üì± **Mobile Health Apps**: Skin lesion classification on smartphones\n",
    "- ‚åö **Wearable Devices**: Heart rate anomaly detection on smartwatches\n",
    "- üè• **Point-of-Care Systems**: Real-time diagnosis in clinics\n",
    "- üåç **Resource-Constrained Settings**: Medical AI in developing countries\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different compression ratios\n",
    "- Try on real medical imaging datasets\n",
    "- Deploy models to mobile devices (TensorFlow Lite, Core ML)\n",
    "- Measure actual inference time and battery consumption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
