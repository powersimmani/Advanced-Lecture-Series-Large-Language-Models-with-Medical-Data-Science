{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Next-Generation Medical AI: Hands-on Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [Mixture of Experts (MoE) Basics](#practice-1-mixture-of-experts-moe-basics)\n",
    "2. [Sparse Activation and Routing](#practice-2-sparse-activation-and-routing)\n",
    "3. [Long-Context Attention Mechanisms](#practice-3-long-context-attention-mechanisms)\n",
    "4. [Flash Attention Simulation](#practice-4-flash-attention-simulation)\n",
    "5. [Retrieval-Augmented Generation (RAG)](#practice-5-retrieval-augmented-generation-rag)\n",
    "6. [Graph Neural Networks for Medical Data](#practice-6-graph-neural-networks-for-medical-data)\n",
    "7. [State Space Models (Mamba-style)](#practice-7-state-space-models-mamba-style)\n",
    "8. [Performance Comparison](#practice-8-performance-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Mixture of Experts (MoE) Basics\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the MoE architecture with gating mechanism\n",
    "- Implement sparse expert selection (Top-K routing)\n",
    "- Visualize expert specialization\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Mixture of Experts:** Multiple specialized sub-networks (experts) with a gating network that routes inputs to the most relevant experts.\n",
    "- **Gating Network:** Selects top-K experts based on input\n",
    "- **Sparse Activation:** Only K out of N experts are active per input\n",
    "- **Efficiency:** Massive scaling with manageable computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Simple MoE Implementation\n",
    "class SimpleMoE(nn.Module):\n",
    "    \"\"\"A simple Mixture of Experts model\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dim: int, num_experts: int = 8, top_k: int = 2):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        # Create expert networks\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, input_dim)\n",
    "            ) for _ in range(num_experts)\n",
    "        ])\n",
    "        \n",
    "        # Gating network\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Compute gating scores\n",
    "        gate_logits = self.gate(x)  # [batch_size, num_experts]\n",
    "        gate_scores = F.softmax(gate_logits, dim=-1)\n",
    "        \n",
    "        # Select top-k experts\n",
    "        top_k_scores, top_k_indices = torch.topk(gate_scores, self.top_k, dim=-1)\n",
    "        \n",
    "        # Normalize top-k scores\n",
    "        top_k_scores = top_k_scores / top_k_scores.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Compute expert outputs\n",
    "        output = torch.zeros_like(x)\n",
    "        for i in range(self.top_k):\n",
    "            expert_idx = top_k_indices[:, i]\n",
    "            expert_weight = top_k_scores[:, i].unsqueeze(-1)\n",
    "            \n",
    "            for batch_idx, exp_idx in enumerate(expert_idx):\n",
    "                expert_output = self.experts[exp_idx](x[batch_idx:batch_idx+1])\n",
    "                output[batch_idx:batch_idx+1] += expert_weight[batch_idx] * expert_output\n",
    "        \n",
    "        return output, top_k_indices, top_k_scores\n",
    "\n",
    "# Test the MoE model\n",
    "def test_moe():\n",
    "    \"\"\"Test MoE with sample data\"\"\"\n",
    "    \n",
    "    # Create sample medical data (simulating patient features)\n",
    "    batch_size = 5\n",
    "    input_dim = 10\n",
    "    \n",
    "    # Simulate different types of medical data\n",
    "    medical_specialties = ['Radiology', 'Pathology', 'Cardiology', 'Neurology', \n",
    "                          'Oncology', 'Genomics', 'Surgery', 'General']\n",
    "    \n",
    "    X = torch.randn(batch_size, input_dim)\n",
    "    \n",
    "    # Create MoE model\n",
    "    model = SimpleMoE(input_dim=input_dim, hidden_dim=32, num_experts=8, top_k=2)\n",
    "    \n",
    "    # Forward pass\n",
    "    output, expert_indices, expert_weights = model(X)\n",
    "    \n",
    "    print(\"üè• Mixture of Experts - Medical Domain Routing\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nInput shape: {X.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Number of experts: {model.num_experts}\")\n",
    "    print(f\"Active experts per input: {model.top_k}\")\n",
    "    \n",
    "    print(\"\\nüìä Expert Selection for Each Sample:\")\n",
    "    print(\"-\" * 60)\n",
    "    for i in range(batch_size):\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        for j in range(model.top_k):\n",
    "            expert_id = expert_indices[i, j].item()\n",
    "            weight = expert_weights[i, j].item()\n",
    "            specialty = medical_specialties[expert_id]\n",
    "            print(f\"  Expert {expert_id} ({specialty}): {weight:.4f} weight\")\n",
    "    \n",
    "    # Calculate computation savings\n",
    "    active_experts = model.top_k\n",
    "    total_experts = model.num_experts\n",
    "    compute_savings = (1 - active_experts / total_experts) * 100\n",
    "    \n",
    "    print(\"\\nüí° Efficiency Gains:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Active experts: {active_experts}/{total_experts} ({active_experts/total_experts*100:.1f}%)\")\n",
    "    print(f\"Computation savings: {compute_savings:.1f}%\")\n",
    "    print(f\"Effective parameter scaling: {total_experts/active_experts:.1f}x\")\n",
    "    \n",
    "    return model, X, output\n",
    "\n",
    "moe_model, sample_input, moe_output = test_moe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Sparse Activation and Routing\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Visualize expert utilization patterns\n",
    "- Understand load balancing in MoE\n",
    "- Compare dense vs sparse activation\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Sparse Activation:** Only a small subset of experts process each input\n",
    "- **Benefits:** Reduced computation, memory efficiency, specialized expertise\n",
    "- **Challenge:** Load balancing - ensuring all experts are utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Visualize Expert Routing Patterns\n",
    "def visualize_expert_routing(num_samples: int = 100):\n",
    "    \"\"\"Visualize which experts are selected for different inputs\"\"\"\n",
    "    \n",
    "    # Generate diverse medical data samples\n",
    "    X = torch.randn(num_samples, 10)\n",
    "    \n",
    "    # Forward pass through MoE\n",
    "    with torch.no_grad():\n",
    "        _, expert_indices, expert_weights = moe_model(X)\n",
    "    \n",
    "    # Count expert usage\n",
    "    expert_usage = torch.zeros(moe_model.num_experts)\n",
    "    for i in range(num_samples):\n",
    "        for j in range(moe_model.top_k):\n",
    "            expert_usage[expert_indices[i, j]] += expert_weights[i, j].item()\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Expert utilization\n",
    "    specialties = ['Radiology', 'Pathology', 'Cardiology', 'Neurology', \n",
    "                   'Oncology', 'Genomics', 'Surgery', 'General']\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(specialties)))\n",
    "    bars = ax1.bar(range(moe_model.num_experts), expert_usage.numpy(), color=colors)\n",
    "    ax1.set_xlabel('Expert ID')\n",
    "    ax1.set_ylabel('Total Weight (Usage)')\n",
    "    ax1.set_title('Expert Utilization Pattern')\n",
    "    ax1.set_xticks(range(moe_model.num_experts))\n",
    "    ax1.set_xticklabels([f'E{i}\\n{s[:4]}' for i, s in enumerate(specialties)], rotation=0, fontsize=9)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add average line\n",
    "    avg_usage = expert_usage.mean().item()\n",
    "    ax1.axhline(y=avg_usage, color='r', linestyle='--', linewidth=2, label=f'Average: {avg_usage:.1f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: Routing heatmap\n",
    "    routing_matrix = torch.zeros(num_samples, moe_model.num_experts)\n",
    "    for i in range(num_samples):\n",
    "        for j in range(moe_model.top_k):\n",
    "            routing_matrix[i, expert_indices[i, j]] = expert_weights[i, j].item()\n",
    "    \n",
    "    im = ax2.imshow(routing_matrix[:20].numpy(), aspect='auto', cmap='YlOrRd')\n",
    "    ax2.set_xlabel('Expert ID')\n",
    "    ax2.set_ylabel('Sample ID')\n",
    "    ax2.set_title('Expert Routing Heatmap (First 20 samples)')\n",
    "    ax2.set_xticks(range(moe_model.num_experts))\n",
    "    ax2.set_xticklabels([f'E{i}' for i in range(moe_model.num_experts)])\n",
    "    plt.colorbar(im, ax=ax2, label='Routing Weight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"üìà Expert Usage Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Most used expert: Expert {expert_usage.argmax().item()} ({specialties[expert_usage.argmax().item()]})\")\n",
    "    print(f\"Least used expert: Expert {expert_usage.argmin().item()} ({specialties[expert_usage.argmin().item()]})\")\n",
    "    print(f\"Usage ratio (max/min): {expert_usage.max()/expert_usage.min():.2f}x\")\n",
    "    print(f\"\\nLoad balance score: {1 - (expert_usage.std() / expert_usage.mean()):.2%}\")\n",
    "    print(\"  (Higher is better, 100% = perfect balance)\")\n",
    "\n",
    "visualize_expert_routing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Long-Context Attention Mechanisms\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Compare standard attention vs efficient attention\n",
    "- Understand complexity trade-offs: O(n¬≤) vs O(n)\n",
    "- Visualize attention patterns on long sequences\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Attention Complexity:**\n",
    "- Standard Attention: O(n¬≤) memory and compute\n",
    "- Flash Attention: O(n) memory with block-wise computation\n",
    "- Critical for processing 100K+ token sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Compare Attention Mechanisms\n",
    "def compare_attention_complexity():\n",
    "    \"\"\"Compare memory usage of different attention mechanisms\"\"\"\n",
    "    \n",
    "    sequence_lengths = [512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 100000]\n",
    "    \n",
    "    # Calculate memory usage (in GB)\n",
    "    def standard_attention_memory(n, d=64):\n",
    "        \"\"\"Memory for standard attention: O(n¬≤)\"\"\"\n",
    "        # Attention matrix: n x n, each element is 4 bytes (float32)\n",
    "        return (n * n * 4) / (1024**3)\n",
    "    \n",
    "    def linear_attention_memory(n, d=64):\n",
    "        \"\"\"Memory for linear attention: O(n)\"\"\"\n",
    "        # Linear in sequence length\n",
    "        return (n * d * 4) / (1024**3)\n",
    "    \n",
    "    standard_mem = [standard_attention_memory(n) for n in sequence_lengths]\n",
    "    linear_mem = [linear_attention_memory(n) for n in sequence_lengths]\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Memory usage comparison\n",
    "    ax1.plot(sequence_lengths, standard_mem, 'o-', linewidth=2, markersize=8, \n",
    "             label='Standard Attention O(n¬≤)', color='#dc3545')\n",
    "    ax1.plot(sequence_lengths, linear_mem, 's-', linewidth=2, markersize=8,\n",
    "             label='Linear Attention O(n)', color='#28a745')\n",
    "    \n",
    "    ax1.set_xlabel('Sequence Length (tokens)', fontsize=12)\n",
    "    ax1.set_ylabel('Memory Usage (GB)', fontsize=12)\n",
    "    ax1.set_title('Attention Mechanism Memory Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(fontsize=11)\n",
    "    \n",
    "    # Add 100K token marker\n",
    "    idx_100k = sequence_lengths.index(100000)\n",
    "    ax1.axvline(x=100000, color='blue', linestyle='--', alpha=0.5, label='100K tokens')\n",
    "    ax1.annotate('100K tokens\\n(Full patient history)', \n",
    "                xy=(100000, standard_mem[idx_100k]),\n",
    "                xytext=(50000, standard_mem[idx_100k]*2),\n",
    "                arrowprops=dict(arrowstyle='->', color='blue'),\n",
    "                fontsize=10, color='blue')\n",
    "    \n",
    "    # Plot 2: Speedup factor\n",
    "    speedup = [s/l for s, l in zip(standard_mem, linear_mem)]\n",
    "    ax2.plot(sequence_lengths, speedup, 'D-', linewidth=2, markersize=8, color='#1E64C8')\n",
    "    ax2.set_xlabel('Sequence Length (tokens)', fontsize=12)\n",
    "    ax2.set_ylabel('Memory Efficiency (x times)', fontsize=12)\n",
    "    ax2.set_title('Linear Attention Efficiency Gain', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.fill_between(sequence_lengths, 1, speedup, alpha=0.3, color='#1E64C8')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(\"\\nüìä Memory Usage Comparison Table:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Seq Length':<12} {'Standard (GB)':<18} {'Linear (GB)':<15} {'Speedup':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, n in enumerate([512, 2048, 8192, 32768, 100000]):\n",
    "        idx = sequence_lengths.index(n)\n",
    "        print(f\"{n:<12,} {standard_mem[idx]:<18.4f} {linear_mem[idx]:<15.6f} {speedup[idx]:<10.1f}x\")\n",
    "    \n",
    "    print(\"\\nüí° Key Insights:\")\n",
    "    print(\"=\" * 80)\n",
    "    idx_100k = sequence_lengths.index(100000)\n",
    "    print(f\"‚Ä¢ At 100K tokens (full patient history):\")\n",
    "    print(f\"  - Standard attention: {standard_mem[idx_100k]:.2f} GB\")\n",
    "    print(f\"  - Linear attention: {linear_mem[idx_100k]:.4f} GB\")\n",
    "    print(f\"  - Efficiency gain: {speedup[idx_100k]:.0f}x less memory!\")\n",
    "    print(f\"\\n‚Ä¢ This is why Flash Attention and Mamba are crucial for medical AI\")\n",
    "\n",
    "compare_attention_complexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Flash Attention Simulation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand block-wise computation\n",
    "- Simulate memory-efficient attention\n",
    "- Visualize the difference in computation patterns\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Flash Attention Innovation:**\n",
    "- Block-wise computation in SRAM (fast memory)\n",
    "- Minimize HBM (slow memory) access\n",
    "- Achieve exact attention with O(n) memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Simulate Flash Attention Block-wise Processing\n",
    "def simulate_flash_attention():\n",
    "    \"\"\"Simulate block-wise attention computation\"\"\"\n",
    "    \n",
    "    seq_length = 128\n",
    "    block_size = 32\n",
    "    num_blocks = seq_length // block_size\n",
    "    \n",
    "    print(\"‚ö° Flash Attention: Block-wise Computation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Sequence length: {seq_length} tokens\")\n",
    "    print(f\"Block size: {block_size} tokens\")\n",
    "    print(f\"Number of blocks: {num_blocks}\")\n",
    "    \n",
    "    # Simulate attention matrix computation\n",
    "    # Standard: Load entire n√ón matrix\n",
    "    # Flash: Process in blocks\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Standard Attention Pattern\n",
    "    standard_pattern = np.random.rand(seq_length, seq_length)\n",
    "    # Apply causal mask\n",
    "    mask = np.triu(np.ones((seq_length, seq_length)), k=1)\n",
    "    standard_pattern = np.where(mask, 0, standard_pattern)\n",
    "    \n",
    "    im1 = axes[0].imshow(standard_pattern, cmap='YlOrRd', aspect='auto')\n",
    "    axes[0].set_title('Standard Attention\\n(Load entire matrix)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Key/Value Position')\n",
    "    axes[0].set_ylabel('Query Position')\n",
    "    plt.colorbar(im1, ax=axes[0], label='Attention Weight')\n",
    "    \n",
    "    # Flash Attention Pattern with blocks\n",
    "    flash_pattern = standard_pattern.copy()\n",
    "    \n",
    "    # Draw block boundaries\n",
    "    for i in range(0, seq_length, block_size):\n",
    "        axes[1].axhline(y=i, color='blue', linewidth=2, alpha=0.7)\n",
    "        axes[1].axvline(x=i, color='blue', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    im2 = axes[1].imshow(flash_pattern, cmap='YlOrRd', aspect='auto')\n",
    "    axes[1].set_title('Flash Attention\\n(Block-wise processing)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Key/Value Position')\n",
    "    axes[1].set_ylabel('Query Position')\n",
    "    plt.colorbar(im2, ax=axes[1], label='Attention Weight')\n",
    "    \n",
    "    # Highlight one block\n",
    "    highlight_block = 1\n",
    "    start = highlight_block * block_size\n",
    "    end = start + block_size\n",
    "    rect = plt.Rectangle((start, start), block_size, block_size, \n",
    "                         fill=False, edgecolor='green', linewidth=3)\n",
    "    axes[1].add_patch(rect)\n",
    "    axes[1].annotate('Current block\\nin SRAM', xy=(start+block_size/2, start-5),\n",
    "                    ha='center', fontsize=10, color='green', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate memory savings\n",
    "    standard_memory = seq_length * seq_length * 4 / (1024**2)  # MB\n",
    "    flash_memory = block_size * block_size * 4 / (1024**2)  # MB\n",
    "    \n",
    "    print(\"\\nüíæ Memory Usage:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Standard Attention: {standard_memory:.2f} MB (entire matrix)\")\n",
    "    print(f\"Flash Attention: {flash_memory:.2f} MB (one block at a time)\")\n",
    "    print(f\"Memory reduction: {standard_memory/flash_memory:.1f}x\")\n",
    "    \n",
    "    print(\"\\nüöÄ Speed Benefits:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚Ä¢ Reduced HBM access: {num_blocks**2} ‚Üí {num_blocks} operations\")\n",
    "    print(f\"‚Ä¢ Computation stays in fast SRAM\")\n",
    "    print(f\"‚Ä¢ Result: 5-9x faster than standard attention\")\n",
    "\n",
    "simulate_flash_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Implement simple RAG pipeline\n",
    "- Understand vector similarity search\n",
    "- Combine retrieval with generation\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**RAG Components:**\n",
    "1. Document embedding and storage\n",
    "2. Query encoding\n",
    "3. Similarity-based retrieval\n",
    "4. Context-augmented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Simple RAG Implementation\n",
    "class SimpleRAG:\n",
    "    \"\"\"Simple Retrieval-Augmented Generation system\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 128):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "    \n",
    "    def add_documents(self, docs: List[str]):\n",
    "        \"\"\"Add documents to the knowledge base\"\"\"\n",
    "        self.documents.extend(docs)\n",
    "        \n",
    "        # Simple embedding: use random projections (in practice, use BERT, etc.)\n",
    "        for doc in docs:\n",
    "            # Simulate document embedding\n",
    "            embedding = torch.randn(self.embedding_dim)\n",
    "            # Normalize\n",
    "            embedding = embedding / embedding.norm()\n",
    "            self.embeddings.append(embedding)\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 3):\n",
    "        \"\"\"Retrieve most relevant documents\"\"\"\n",
    "        # Encode query (simulate)\n",
    "        query_embedding = torch.randn(self.embedding_dim)\n",
    "        query_embedding = query_embedding / query_embedding.norm()\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = []\n",
    "        for doc_emb in self.embeddings:\n",
    "            similarity = torch.dot(query_embedding, doc_emb).item()\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        # Get top-k\n",
    "        top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        top_k_docs = [self.documents[i] for i in top_k_indices]\n",
    "        top_k_scores = [similarities[i] for i in top_k_indices]\n",
    "        \n",
    "        return top_k_docs, top_k_scores\n",
    "\n",
    "# Test RAG system\n",
    "def test_rag():\n",
    "    \"\"\"Test RAG with medical documents\"\"\"\n",
    "    \n",
    "    # Sample medical knowledge base\n",
    "    medical_docs = [\n",
    "        \"Patient presents with elevated glucose levels and frequent urination - Type 2 Diabetes suspected\",\n",
    "        \"Chest X-ray shows opacity in lower right lobe - possible pneumonia\",\n",
    "        \"EKG reveals ST-segment elevation - acute myocardial infarction\",\n",
    "        \"MRI scan indicates lesion in frontal lobe - further neurological assessment needed\",\n",
    "        \"Blood pressure 180/120 mmHg - hypertensive emergency\",\n",
    "        \"Biopsy results show abnormal cell growth - malignancy confirmed\",\n",
    "        \"Patient history includes multiple hospital admissions for heart failure\",\n",
    "        \"Lab results: HbA1c 9.2% - poor glycemic control\",\n",
    "        \"Genetic testing reveals BRCA1 mutation - increased cancer risk\",\n",
    "        \"Patient exhibits symptoms of depression and anxiety\"\n",
    "    ]\n",
    "    \n",
    "    # Create RAG system\n",
    "    rag = SimpleRAG(embedding_dim=128)\n",
    "    rag.add_documents(medical_docs)\n",
    "    \n",
    "    # Test queries\n",
    "    queries = [\n",
    "        \"Patient with high blood sugar\",\n",
    "        \"Heart attack symptoms\",\n",
    "        \"Brain imaging results\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üîç Retrieval-Augmented Generation Demo\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Knowledge Base: {len(medical_docs)} medical documents\")\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Query: '{query}'\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        retrieved_docs, scores = rag.retrieve(query, top_k=3)\n",
    "        \n",
    "        print(\"\\nTop 3 Retrieved Documents:\")\n",
    "        for i, (doc, score) in enumerate(zip(retrieved_docs, scores), 1):\n",
    "            print(f\"\\n{i}. [Similarity: {score:.4f}]\")\n",
    "            print(f\"   {doc}\")\n",
    "    \n",
    "    # Visualize retrieval\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    query = \"Patient with high blood sugar\"\n",
    "    retrieved_docs, scores = rag.retrieve(query, top_k=len(medical_docs))\n",
    "    \n",
    "    colors = ['green' if score > 0.5 else 'orange' if score > 0.3 else 'lightgray' \n",
    "              for score in scores]\n",
    "    \n",
    "    bars = ax.barh(range(len(scores)), scores, color=colors)\n",
    "    ax.set_yticks(range(len(scores)))\n",
    "    ax.set_yticklabels([f\"Doc {i+1}\" for i in range(len(scores))], fontsize=9)\n",
    "    ax.set_xlabel('Cosine Similarity Score', fontsize=11)\n",
    "    ax.set_title(f'Document Relevance for Query: \"{query}\"', fontsize=12, fontweight='bold')\n",
    "    ax.axvline(x=0.5, color='red', linestyle='--', linewidth=2, alpha=0.5, label='High relevance threshold')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° RAG Benefits for Medical AI:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"‚úì Access to vast medical knowledge without model retraining\")\n",
    "    print(\"‚úì Up-to-date information from latest research\")\n",
    "    print(\"‚úì Explainable: can cite retrieved sources\")\n",
    "    print(\"‚úì Efficient: unlimited knowledge base size\")\n",
    "    \n",
    "    return rag\n",
    "\n",
    "rag_system = test_rag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: Graph Neural Networks for Medical Data\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand graph representation of medical relationships\n",
    "- Implement simple message passing\n",
    "- Visualize disease-symptom-drug networks\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Medical Knowledge Graphs:**\n",
    "- Nodes: diseases, symptoms, drugs, genes, proteins\n",
    "- Edges: relationships (causes, treats, interacts)\n",
    "- GNN: Learn representations by aggregating neighbor information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Medical Knowledge Graph Visualization\n",
    "def visualize_medical_graph():\n",
    "    \"\"\"Create and visualize a medical knowledge graph\"\"\"\n",
    "    \n",
    "    # Define nodes\n",
    "    nodes = {\n",
    "        'diseases': ['Type 2 Diabetes', 'Hypertension', 'Heart Disease'],\n",
    "        'symptoms': ['High Blood Glucose', 'Increased Thirst', 'High BP', 'Chest Pain'],\n",
    "        'drugs': ['Metformin', 'Insulin', 'Lisinopril', 'Aspirin'],\n",
    "        'genes': ['TCF7L2', 'PPARG', 'ACE']\n",
    "    }\n",
    "    \n",
    "    # Define edges (relationships)\n",
    "    edges = [\n",
    "        ('Type 2 Diabetes', 'High Blood Glucose', 'causes'),\n",
    "        ('Type 2 Diabetes', 'Increased Thirst', 'causes'),\n",
    "        ('Type 2 Diabetes', 'Metformin', 'treated_by'),\n",
    "        ('Type 2 Diabetes', 'Insulin', 'treated_by'),\n",
    "        ('Type 2 Diabetes', 'TCF7L2', 'associated'),\n",
    "        ('Type 2 Diabetes', 'PPARG', 'associated'),\n",
    "        ('Hypertension', 'High BP', 'causes'),\n",
    "        ('Hypertension', 'Lisinopril', 'treated_by'),\n",
    "        ('Hypertension', 'ACE', 'associated'),\n",
    "        ('Heart Disease', 'Chest Pain', 'causes'),\n",
    "        ('Heart Disease', 'Aspirin', 'treated_by'),\n",
    "    ]\n",
    "    \n",
    "    print(\"üï∏Ô∏è Medical Knowledge Graph\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total nodes: {sum(len(v) for v in nodes.values())}\")\n",
    "    print(f\"Total edges: {len(edges)}\")\n",
    "    print(\"\\nNode types:\")\n",
    "    for node_type, node_list in nodes.items():\n",
    "        print(f\"  ‚Ä¢ {node_type}: {len(node_list)}\")\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    all_nodes = []\n",
    "    for node_list in nodes.values():\n",
    "        all_nodes.extend(node_list)\n",
    "    \n",
    "    node_to_idx = {node: i for i, node in enumerate(all_nodes)}\n",
    "    n_nodes = len(all_nodes)\n",
    "    \n",
    "    adj_matrix = np.zeros((n_nodes, n_nodes))\n",
    "    for src, dst, rel_type in edges:\n",
    "        i, j = node_to_idx[src], node_to_idx[dst]\n",
    "        adj_matrix[i, j] = 1\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: Adjacency matrix\n",
    "    im = ax1.imshow(adj_matrix, cmap='YlOrRd', aspect='auto')\n",
    "    ax1.set_title('Knowledge Graph Adjacency Matrix', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Node Index')\n",
    "    ax1.set_ylabel('Node Index')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=ax1, label='Connection (1=connected)')\n",
    "    \n",
    "    # Plot 2: Node degree distribution\n",
    "    degrees = adj_matrix.sum(axis=1) + adj_matrix.sum(axis=0)\n",
    "    \n",
    "    colors_by_type = []\n",
    "    labels_by_type = []\n",
    "    start_idx = 0\n",
    "    color_map = {'diseases': '#ff6b6b', 'symptoms': '#4ecdc4', \n",
    "                 'drugs': '#95e1d3', 'genes': '#feca57'}\n",
    "    \n",
    "    for node_type, node_list in nodes.items():\n",
    "        end_idx = start_idx + len(node_list)\n",
    "        colors_by_type.extend([color_map[node_type]] * len(node_list))\n",
    "        labels_by_type.extend([node_type] * len(node_list))\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    bars = ax2.bar(range(n_nodes), degrees, color=colors_by_type)\n",
    "    ax2.set_xlabel('Node Index', fontsize=11)\n",
    "    ax2.set_ylabel('Node Degree (# connections)', fontsize=11)\n",
    "    ax2.set_title('Node Connectivity', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=color, label=node_type) \n",
    "                      for node_type, color in color_map.items()]\n",
    "    ax2.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Graph Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Average degree: {degrees.mean():.2f}\")\n",
    "    print(f\"Max degree: {degrees.max():.0f}\")\n",
    "    print(f\"Most connected node: {all_nodes[int(degrees.argmax())]}\")\n",
    "    \n",
    "    print(\"\\nüí° GNN Benefits:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚úì Model complex medical relationships\")\n",
    "    print(\"‚úì Drug repurposing through graph analysis\")\n",
    "    print(\"‚úì Predict disease comorbidities\")\n",
    "    print(\"‚úì Discover new biomarkers\")\n",
    "    \n",
    "    return adj_matrix, all_nodes\n",
    "\n",
    "adj_matrix, graph_nodes = visualize_medical_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 7: State Space Models (Mamba-style)\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand linear complexity sequence modeling\n",
    "- Compare RNN, Transformer, and State Space approaches\n",
    "- Simulate continuous-time dynamics\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**State Space Models (SSM):**\n",
    "- Continuous-time dynamics: h'(t) = Ah(t) + Bx(t)\n",
    "- Linear complexity: O(n) vs Transformer's O(n¬≤)\n",
    "- Selective mechanism: Input-dependent transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Simple State Space Model\n",
    "class SimpleSSM(nn.Module):\n",
    "    \"\"\"Simplified State Space Model\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, d_state: int = 16):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        \n",
    "        # State space parameters\n",
    "        self.A = nn.Parameter(torch.randn(d_state, d_state) * 0.01)\n",
    "        self.B = nn.Parameter(torch.randn(d_state, d_model) * 0.01)\n",
    "        self.C = nn.Parameter(torch.randn(d_model, d_state) * 0.01)\n",
    "        self.D = nn.Parameter(torch.randn(d_model) * 0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass with linear scan\"\"\"\n",
    "        batch, length, dim = x.shape\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        h = torch.zeros(batch, self.d_state, device=x.device)\n",
    "        outputs = []\n",
    "        \n",
    "        # Linear scan (this is the key advantage!)\n",
    "        for t in range(length):\n",
    "            # State update: h(t) = A¬∑h(t-1) + B¬∑x(t)\n",
    "            h = h @ self.A.T + x[:, t] @ self.B.T\n",
    "            \n",
    "            # Output: y(t) = C¬∑h(t) + D¬∑x(t)\n",
    "            y = h @ self.C.T + x[:, t] * self.D\n",
    "            outputs.append(y)\n",
    "        \n",
    "        return torch.stack(outputs, dim=1)\n",
    "\n",
    "# Test SSM\n",
    "def test_ssm():\n",
    "    \"\"\"Test State Space Model\"\"\"\n",
    "    \n",
    "    # Simulate medical time-series (e.g., continuous glucose monitoring)\n",
    "    batch_size = 1\n",
    "    seq_length = 1000  # 1000 time steps\n",
    "    d_model = 8\n",
    "    \n",
    "    # Generate synthetic time-series\n",
    "    t = torch.linspace(0, 10, seq_length)\n",
    "    # Multiple sine waves with different frequencies (simulating physiological signals)\n",
    "    x = torch.zeros(batch_size, seq_length, d_model)\n",
    "    for i in range(d_model):\n",
    "        freq = 0.5 + i * 0.3\n",
    "        x[0, :, i] = torch.sin(2 * np.pi * freq * t) + torch.randn(seq_length) * 0.1\n",
    "    \n",
    "    # Create SSM\n",
    "    ssm = SimpleSSM(d_model=d_model, d_state=32)\n",
    "    \n",
    "    print(\"üîÑ State Space Model Demo\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in ssm.parameters())}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    import time\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = ssm(x)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Processing time: {elapsed*1000:.2f} ms\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "    \n",
    "    # Plot input signals\n",
    "    for i in range(min(3, d_model)):\n",
    "        axes[0, 0].plot(t.numpy(), x[0, :, i].numpy(), label=f'Signal {i+1}', alpha=0.7)\n",
    "    axes[0, 0].set_title('Input Time Series (Medical Signals)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Time')\n",
    "    axes[0, 0].set_ylabel('Value')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Plot output\n",
    "    for i in range(min(3, d_model)):\n",
    "        axes[0, 1].plot(t.numpy(), output[0, :, i].detach().numpy(), \n",
    "                       label=f'Output {i+1}', alpha=0.7)\n",
    "    axes[0, 1].set_title('SSM Output', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Time')\n",
    "    axes[0, 1].set_ylabel('Value')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # State matrix A visualization\n",
    "    im1 = axes[1, 0].imshow(ssm.A.detach().numpy(), cmap='RdBu', aspect='auto')\n",
    "    axes[1, 0].set_title('State Transition Matrix A', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('State Dimension')\n",
    "    axes[1, 0].set_ylabel('State Dimension')\n",
    "    plt.colorbar(im1, ax=axes[1, 0])\n",
    "    \n",
    "    # Complexity comparison\n",
    "    seq_lengths = [100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "    transformer_complexity = [n**2 for n in seq_lengths]\n",
    "    ssm_complexity = [n for n in seq_lengths]\n",
    "    \n",
    "    axes[1, 1].plot(seq_lengths, transformer_complexity, 'o-', label='Transformer O(n¬≤)', \n",
    "                   color='#dc3545', linewidth=2)\n",
    "    axes[1, 1].plot(seq_lengths, ssm_complexity, 's-', label='SSM O(n)', \n",
    "                   color='#28a745', linewidth=2)\n",
    "    axes[1, 1].set_xscale('log')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].set_xlabel('Sequence Length', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Computational Complexity', fontsize=11)\n",
    "    axes[1, 1].set_title('Complexity Comparison', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° SSM Advantages for Medical AI:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚úì Linear complexity: O(n) vs Transformer's O(n¬≤)\")\n",
    "    print(\"‚úì Perfect for long medical time-series (ICU monitoring, EEG)\")\n",
    "    print(\"‚úì Continuous-time modeling of physiological dynamics\")\n",
    "    print(\"‚úì Efficient on both training and inference\")\n",
    "    \n",
    "    return ssm\n",
    "\n",
    "ssm_model = test_ssm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 8: Performance Comparison\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Compare all architectures on key metrics\n",
    "- Understand trade-offs between approaches\n",
    "- Make informed architecture choices\n",
    "\n",
    "### üìñ Key Metrics\n",
    "- **Computational Complexity:** Time and memory\n",
    "- **Accuracy:** Task-specific performance\n",
    "- **Scalability:** How well does it scale?\n",
    "- **Deployment:** Practical considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Comprehensive Architecture Comparison\n",
    "def architecture_comparison():\n",
    "    \"\"\"Compare different architectures\"\"\"\n",
    "    \n",
    "    architectures = {\n",
    "        'Dense Transformer': {\n",
    "            'complexity_time': 'O(n¬≤)',\n",
    "            'complexity_memory': 'O(n¬≤)',\n",
    "            'max_seq_length': 2048,\n",
    "            'accuracy': 0.92,\n",
    "            'inference_speed': 1.0,\n",
    "            'color': '#dc3545'\n",
    "        },\n",
    "        'MoE': {\n",
    "            'complexity_time': 'O(n¬≤/N√óK)',\n",
    "            'complexity_memory': 'O(n¬≤/N√óK)',\n",
    "            'max_seq_length': 2048,\n",
    "            'accuracy': 0.94,\n",
    "            'inference_speed': 2.5,\n",
    "            'color': '#ffc107'\n",
    "        },\n",
    "        'Flash Attention': {\n",
    "            'complexity_time': 'O(n¬≤)',\n",
    "            'complexity_memory': 'O(n)',\n",
    "            'max_seq_length': 100000,\n",
    "            'accuracy': 0.92,\n",
    "            'inference_speed': 7.0,\n",
    "            'color': '#1E64C8'\n",
    "        },\n",
    "        'Mamba (SSM)': {\n",
    "            'complexity_time': 'O(n)',\n",
    "            'complexity_memory': 'O(n)',\n",
    "            'max_seq_length': 1000000,\n",
    "            'accuracy': 0.91,\n",
    "            'inference_speed': 10.0,\n",
    "            'color': '#28a745'\n",
    "        },\n",
    "        'Graph Transformer': {\n",
    "            'complexity_time': 'O(E)',\n",
    "            'complexity_memory': 'O(V+E)',\n",
    "            'max_seq_length': 'N/A',\n",
    "            'accuracy': 0.89,\n",
    "            'inference_speed': 3.0,\n",
    "            'color': '#a29bfe'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"üìä Architecture Comparison Table\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"{'Architecture':<20} {'Time':<15} {'Memory':<15} {'Max Length':<12} {'Accuracy':<10} {'Speed':<8}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for name, specs in architectures.items():\n",
    "        print(f\"{name:<20} {specs['complexity_time']:<15} {specs['complexity_memory']:<15} \"\n",
    "              f\"{str(specs['max_seq_length']):<12} {specs['accuracy']:<10.2f} {specs['inference_speed']:<8.1f}x\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Plot 1: Accuracy comparison\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    names = list(architectures.keys())\n",
    "    accuracies = [specs['accuracy'] for specs in architectures.values()]\n",
    "    colors = [specs['color'] for specs in architectures.values()]\n",
    "    \n",
    "    bars = ax1.bar(names, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax1.set_title('Model Accuracy on Medical Tasks', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylim([0.85, 0.95])\n",
    "    ax1.axhline(y=0.90, color='red', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Inference speed\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    speeds = [specs['inference_speed'] for specs in architectures.values()]\n",
    "    ax2.barh(names, speeds, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    ax2.set_xlabel('Relative Speed (x times)', fontsize=11)\n",
    "    ax2.set_title('Inference Speed', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Max sequence length\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    max_lengths = [specs['max_seq_length'] if isinstance(specs['max_seq_length'], int) \n",
    "                   else 0 for specs in architectures.values()]\n",
    "    valid_names = [name for name, length in zip(names, max_lengths) if length > 0]\n",
    "    valid_lengths = [length for length in max_lengths if length > 0]\n",
    "    valid_colors = [color for color, length in zip(colors, max_lengths) if length > 0]\n",
    "    \n",
    "    ax3.barh(valid_names, valid_lengths, color=valid_colors, alpha=0.7, \n",
    "             edgecolor='black', linewidth=1.5)\n",
    "    ax3.set_xlabel('Max Sequence Length (tokens)', fontsize=11)\n",
    "    ax3.set_title('Context Window Size', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add 100K marker\n",
    "    ax3.axvline(x=100000, color='blue', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    ax3.text(100000, len(valid_names)-0.5, '100K\\n(Patient history)', \n",
    "            ha='left', va='center', fontsize=9, color='blue')\n",
    "    \n",
    "    # Plot 4: Use case matrix\n",
    "    ax4 = fig.add_subplot(gs[1, 2])\n",
    "    use_cases = ['Short Seq', 'Long Seq', 'Graph Data', 'Time Series', 'Real-time']\n",
    "    suitability = np.array([\n",
    "        [1.0, 0.3, 0.2, 0.7, 0.4],  # Dense Transformer\n",
    "        [1.0, 0.3, 0.2, 0.7, 0.6],  # MoE\n",
    "        [0.9, 1.0, 0.2, 0.8, 0.7],  # Flash Attention\n",
    "        [0.8, 1.0, 0.2, 1.0, 0.9],  # Mamba\n",
    "        [0.6, 0.5, 1.0, 0.6, 0.7],  # Graph Transformer\n",
    "    ])\n",
    "    \n",
    "    im = ax4.imshow(suitability, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "    ax4.set_xticks(range(len(use_cases)))\n",
    "    ax4.set_yticks(range(len(names)))\n",
    "    ax4.set_xticklabels(use_cases, rotation=45, ha='right', fontsize=9)\n",
    "    ax4.set_yticklabels(names, fontsize=9)\n",
    "    ax4.set_title('Suitability Matrix', fontsize=12, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax4, label='Suitability (0-1)')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(names)):\n",
    "        for j in range(len(use_cases)):\n",
    "            text = ax4.text(j, i, f'{suitability[i, j]:.1f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "    \n",
    "    # Plot 5: Radar chart comparison\n",
    "    ax5 = fig.add_subplot(gs[2, :], projection='polar')\n",
    "    \n",
    "    categories = ['Accuracy', 'Speed', 'Memory Eff.', 'Scalability', 'Versatility']\n",
    "    N = len(categories)\n",
    "    \n",
    "    # Normalize scores\n",
    "    scores = {\n",
    "        'Dense Transformer': [0.92, 0.10, 0.30, 0.20, 0.90],\n",
    "        'MoE': [0.94, 0.25, 0.35, 0.60, 0.85],\n",
    "        'Flash Attention': [0.92, 0.70, 0.95, 0.90, 0.90],\n",
    "        'Mamba (SSM)': [0.91, 1.00, 1.00, 1.00, 0.80],\n",
    "    }\n",
    "    \n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    for name, score in scores.items():\n",
    "        values = score + score[:1]\n",
    "        ax5.plot(angles, values, 'o-', linewidth=2, label=name, \n",
    "                color=architectures[name]['color'])\n",
    "        ax5.fill(angles, values, alpha=0.15, color=architectures[name]['color'])\n",
    "    \n",
    "    ax5.set_xticks(angles[:-1])\n",
    "    ax5.set_xticklabels(categories, fontsize=10)\n",
    "    ax5.set_ylim(0, 1)\n",
    "    ax5.set_title('Overall Performance Profile', fontsize=13, fontweight='bold', pad=20)\n",
    "    ax5.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=9)\n",
    "    ax5.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Architecture Selection Guide:\")\n",
    "    print(\"=\" * 90)\n",
    "    print(\"‚úì Short sequences (<2K tokens): Dense Transformer or MoE\")\n",
    "    print(\"‚úì Long context (100K+ tokens): Flash Attention or Mamba\")\n",
    "    print(\"‚úì Graph/relational data: Graph Transformers\")\n",
    "    print(\"‚úì Time-series (ICU monitoring): Mamba (SSM)\")\n",
    "    print(\"‚úì Large-scale deployment: MoE with Flash Attention\")\n",
    "    print(\"‚úì Real-time inference: Mamba or optimized MoE\")\n",
    "\n",
    "architecture_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **Mixture of Experts (MoE)**\n",
    "   - Sparse activation enables efficient scaling\n",
    "   - Top-K routing selects specialized experts\n",
    "   - 75% computation reduction with minimal accuracy loss\n",
    "\n",
    "2. **Long-Context Models**\n",
    "   - Flash Attention: O(n) memory vs standard O(n¬≤)\n",
    "   - Essential for processing 100K+ token patient histories\n",
    "   - 5-9x faster than standard attention\n",
    "\n",
    "3. **Novel Architectures**\n",
    "   - **RAG**: Unlimited knowledge base access\n",
    "   - **Graph Transformers**: Model medical relationships\n",
    "   - **Mamba (SSM)**: Linear complexity for time-series\n",
    "\n",
    "4. **Performance Comparison**\n",
    "   - Each architecture excels at different tasks\n",
    "   - Trade-offs between accuracy, speed, and scalability\n",
    "   - Hybrid approaches often yield best results\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **Efficiency matters**: Flash Attention and Mamba enable practical long-context processing\n",
    "- **Specialization helps**: MoE and Graph models leverage domain structure\n",
    "- **No single winner**: Choose architecture based on your specific use case\n",
    "\n",
    "### Medical AI Applications:\n",
    "\n",
    "- **MoE**: Multi-specialty diagnostic systems\n",
    "- **Long-Context**: Comprehensive patient history analysis\n",
    "- **RAG**: Always up-to-date medical knowledge\n",
    "- **Graph**: Drug discovery and disease networks\n",
    "- **SSM**: Continuous monitoring (ICU, wearables)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Experiment with pre-trained models (Hugging Face)\n",
    "2. Fine-tune on medical datasets\n",
    "3. Explore hybrid architectures\n",
    "4. Stay updated on emerging techniques (2025+)\n",
    "\n",
    "### üîÆ Future Outlook (2025-2030):\n",
    "\n",
    "- **2025-2027**: 1M+ context models, clinical MoE deployment\n",
    "- **2027-2029**: Quantum ML begins, neuromorphic devices\n",
    "- **2030+**: Hybrid bio-AI systems, personalized AI for every patient\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Further Resources\n",
    "\n",
    "### Papers to Read:\n",
    "- Switch Transformer (Google, 2021)\n",
    "- Flash Attention v2 (Dao et al., 2023)\n",
    "- Mamba: Linear-Time Sequence Modeling (Gu & Dao, 2023)\n",
    "- Graph Transformer Networks (Dwivedi & Bresson, 2020)\n",
    "\n",
    "### Libraries to Explore:\n",
    "- **DeepSpeed-MoE**: Efficient MoE training\n",
    "- **Flash Attention**: Fast attention implementation\n",
    "- **PyTorch Geometric**: Graph neural networks\n",
    "- **Hugging Face Transformers**: Pre-trained models\n",
    "\n",
    "### Datasets:\n",
    "- MIMIC-III / MIMIC-IV: ICU time-series\n",
    "- MedQA: Medical question answering\n",
    "- BioASQ: Biomedical semantic indexing\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Keep exploring and building the future of Medical AI!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
