{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Explainable Medical AI: Hands-On Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Preparation](#practice-1-setup-and-data-preparation)\n",
    "2. [Attention Visualization](#practice-2-attention-visualization)\n",
    "3. [SHAP Values for Medical Predictions](#practice-3-shap-values-for-medical-predictions)\n",
    "4. [LIME for Clinical Text](#practice-4-lime-for-clinical-text)\n",
    "5. [Integrated Gradients](#practice-5-integrated-gradients)\n",
    "6. [Counterfactual Explanations](#practice-6-counterfactual-explanations)\n",
    "7. [Model Comparison: Performance vs Interpretability](#practice-7-model-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install shap lime captum torch torchvision\n",
    "\n",
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# XAI libraries\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Setup and Data Preparation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Load and prepare medical data for XAI analysis\n",
    "- Understand the structure of clinical datasets\n",
    "- Create a baseline prediction model\n",
    "\n",
    "### üìñ Key Concepts\n",
    "We'll simulate a **heart disease risk prediction** scenario with patient features like age, blood pressure, cholesterol, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Generate synthetic medical data\n",
    "def generate_medical_data(n_samples=500):\n",
    "    \"\"\"\n",
    "    Generate synthetic medical data for heart disease prediction\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate features\n",
    "    age = np.random.randint(30, 80, n_samples)\n",
    "    blood_pressure = np.random.randint(110, 180, n_samples)\n",
    "    cholesterol = np.random.randint(150, 300, n_samples)\n",
    "    bmi = np.random.uniform(18, 40, n_samples)\n",
    "    exercise_hours = np.random.uniform(0, 10, n_samples)\n",
    "    smoking = np.random.randint(0, 2, n_samples)\n",
    "    diabetes = np.random.randint(0, 2, n_samples)\n",
    "    \n",
    "    # Create risk score (higher score = higher risk)\n",
    "    risk_score = (\n",
    "        0.5 * (age - 30) / 50 +\n",
    "        0.3 * (blood_pressure - 110) / 70 +\n",
    "        0.2 * (cholesterol - 150) / 150 +\n",
    "        0.2 * (bmi - 18) / 22 +\n",
    "        -0.3 * exercise_hours / 10 +\n",
    "        0.4 * smoking +\n",
    "        0.3 * diabetes\n",
    "    )\n",
    "    \n",
    "    # Convert to binary outcome (1 = high risk, 0 = low risk)\n",
    "    # Add some randomness\n",
    "    risk_prob = 1 / (1 + np.exp(-2 * (risk_score - 0.5)))\n",
    "    high_risk = (np.random.random(n_samples) < risk_prob).astype(int)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'Age': age,\n",
    "        'Blood_Pressure': blood_pressure,\n",
    "        'Cholesterol': cholesterol,\n",
    "        'BMI': bmi,\n",
    "        'Exercise_Hours': exercise_hours,\n",
    "        'Smoking': smoking,\n",
    "        'Diabetes': diabetes,\n",
    "        'High_Risk': high_risk\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate data\n",
    "medical_data = generate_medical_data(500)\n",
    "\n",
    "print(\"Medical Dataset Overview:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(medical_data)}\")\n",
    "print(f\"High risk patients: {medical_data['High_Risk'].sum()} ({medical_data['High_Risk'].mean()*100:.1f}%)\")\n",
    "print(f\"Low risk patients: {(1-medical_data['High_Risk']).sum()} ({(1-medical_data['High_Risk'].mean())*100:.1f}%)\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(medical_data.head())\n",
    "\n",
    "print(\"\\nFeature Statistics:\")\n",
    "display(medical_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Train baseline models\n",
    "def train_baseline_models(data):\n",
    "    \"\"\"\n",
    "    Train multiple models for comparison\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X = data.drop('High_Risk', axis=1)\n",
    "    y = data['High_Risk']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train multiple models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"Model Training Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Train\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        print(f\"{name:25s} | Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return models, results, X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test, scaler\n",
    "\n",
    "models, results, X_train_scaled, X_test_scaled, y_train, y_test, X_train, X_test, scaler = train_baseline_models(medical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Attention Visualization (Feature Importance)\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Visualize which features the model focuses on\n",
    "- Understand feature importance in tree-based models\n",
    "- Create attention-like heatmaps\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Feature Importance** in tree-based models shows which features are most influential in making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Visualize feature importance\n",
    "def visualize_feature_importance(model, feature_names, model_name):\n",
    "    \"\"\"\n",
    "    Create attention-like visualization of feature importance\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        print(f\"Model {model_name} does not have feature importance\")\n",
    "        return\n",
    "    \n",
    "    # Normalize importances\n",
    "    importances = importances / importances.sum()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = plt.cm.RdYlGn_r(importances / importances.max())\n",
    "    bars = ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "    \n",
    "    ax.set_xlabel('Importance (Attention Weight)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Feature Importance - {model_name}', fontsize=14, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.3f}', ha='left', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Visualize for Random Forest\n",
    "feature_names = medical_data.drop('High_Risk', axis=1).columns.tolist()\n",
    "rf_importance = visualize_feature_importance(\n",
    "    results['Random Forest']['model'], \n",
    "    feature_names, \n",
    "    'Random Forest'\n",
    ")\n",
    "\n",
    "print(\"\\nüéØ Key Insight: The model 'pays attention' to these features most!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: SHAP Values for Medical Predictions\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Calculate SHAP values for individual predictions\n",
    "- Understand how each feature contributes to a specific prediction\n",
    "- Visualize SHAP waterfall and force plots\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**SHAP (SHapley Additive exPlanations):** Game-theoretic approach to explain model predictions by computing the contribution of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Calculate SHAP values\n",
    "def explain_with_shap(model, X_train, X_test, feature_names):\n",
    "    \"\"\"\n",
    "    Use SHAP to explain model predictions\n",
    "    \"\"\"\n",
    "    print(\"Computing SHAP values...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    # For binary classification, take the positive class\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]\n",
    "    \n",
    "    print(f\"‚úÖ SHAP values computed for {len(X_test)} test samples\")\n",
    "    print(f\"Base value (average prediction): {explainer.expected_value:.4f}\")\n",
    "    \n",
    "    return explainer, shap_values\n",
    "\n",
    "# Get SHAP values for Random Forest\n",
    "rf_model = results['Random Forest']['model']\n",
    "explainer_rf, shap_values_rf = explain_with_shap(\n",
    "    rf_model, X_train_scaled, X_test_scaled, feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Visualize SHAP summary plot\n",
    "print(\"SHAP Summary Plot - Overall Feature Impact\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values_rf, X_test_scaled, feature_names=feature_names, show=False)\n",
    "plt.title('SHAP Summary: Feature Impact on Predictions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Interpretation:\")\n",
    "print(\"  - Red dots: High feature values\")\n",
    "print(\"  - Blue dots: Low feature values\")\n",
    "print(\"  - X-axis: SHAP value (impact on model output)\")\n",
    "print(\"  - Features ranked by importance from top to bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Explain a single prediction\n",
    "def explain_single_prediction(idx=0):\n",
    "    \"\"\"\n",
    "    Explain one patient's prediction in detail\n",
    "    \"\"\"\n",
    "    print(f\"Explaining Prediction for Patient #{idx}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get patient data\n",
    "    patient_data = X_test.iloc[idx]\n",
    "    patient_scaled = X_test_scaled[idx:idx+1]\n",
    "    \n",
    "    # Prediction\n",
    "    prediction = rf_model.predict(patient_scaled)[0]\n",
    "    prediction_proba = rf_model.predict_proba(patient_scaled)[0]\n",
    "    \n",
    "    print(\"\\nPatient Information:\")\n",
    "    for feature, value in patient_data.items():\n",
    "        print(f\"  {feature:20s}: {value:.2f}\")\n",
    "    \n",
    "    print(\"\\nModel Prediction:\")\n",
    "    print(f\"  Risk Level: {'HIGH RISK ‚ö†Ô∏è' if prediction == 1 else 'Low Risk ‚úì'}\")\n",
    "    print(f\"  Confidence: {prediction_proba[prediction]*100:.1f}%\")\n",
    "    print(f\"  Probability breakdown: Low={prediction_proba[0]:.3f}, High={prediction_proba[1]:.3f}\")\n",
    "    \n",
    "    # SHAP waterfall plot\n",
    "    print(\"\\nSHAP Waterfall Plot (Feature Contributions):\")\n",
    "    \n",
    "    # Get base value\n",
    "    if isinstance(explainer_rf.expected_value, np.ndarray):\n",
    "        base_value = explainer_rf.expected_value[1]\n",
    "    else:\n",
    "        base_value = explainer_rf.expected_value\n",
    "    \n",
    "    # Create waterfall plot\n",
    "    shap.waterfall_plot(\n",
    "        shap.Explanation(\n",
    "            values=shap_values_rf[idx],\n",
    "            base_values=base_value,\n",
    "            data=patient_scaled[0],\n",
    "            feature_names=feature_names\n",
    "        ),\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature contribution breakdown\n",
    "    print(\"\\nFeature Contribution Breakdown:\")\n",
    "    contributions = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Value': patient_data.values,\n",
    "        'SHAP Value': shap_values_rf[idx],\n",
    "        'Impact': ['Increases Risk' if v > 0 else 'Decreases Risk' for v in shap_values_rf[idx]]\n",
    "    }).sort_values('SHAP Value', key=abs, ascending=False)\n",
    "    \n",
    "    display(contributions)\n",
    "    \n",
    "    return patient_data, prediction, contributions\n",
    "\n",
    "# Explain first test patient\n",
    "patient_info, pred, contrib = explain_single_prediction(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: LIME for Clinical Text\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Apply LIME to tabular medical data\n",
    "- Understand local interpretable approximations\n",
    "- Compare LIME with SHAP explanations\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**LIME (Local Interpretable Model-agnostic Explanations):** Explains predictions by approximating the model locally with an interpretable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 LIME explanation for tabular data\n",
    "def explain_with_lime(model, X_train, X_test, feature_names, idx=0):\n",
    "    \"\"\"\n",
    "    Use LIME to explain a prediction\n",
    "    \"\"\"\n",
    "    print(f\"LIME Explanation for Patient #{idx}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create LIME explainer\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        X_train,\n",
    "        feature_names=feature_names,\n",
    "        class_names=['Low Risk', 'High Risk'],\n",
    "        mode='classification',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Explain instance\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_test[idx],\n",
    "        model.predict_proba,\n",
    "        num_features=len(feature_names)\n",
    "    )\n",
    "    \n",
    "    # Show explanation\n",
    "    print(\"\\nLIME Feature Weights:\")\n",
    "    explanation.show_in_notebook(show_table=True)\n",
    "    \n",
    "    # Get feature weights\n",
    "    lime_weights = explanation.as_list()\n",
    "    \n",
    "    print(\"\\nTop Contributing Features (LIME):\")\n",
    "    for feature, weight in lime_weights[:5]:\n",
    "        direction = \"increases\" if weight > 0 else \"decreases\"\n",
    "        print(f\"  {feature:40s}: {weight:+.4f} ({direction} risk)\")\n",
    "    \n",
    "    return explanation, lime_weights\n",
    "\n",
    "# Explain with LIME\n",
    "lime_explanation, lime_weights = explain_with_lime(\n",
    "    rf_model, X_train_scaled, X_test_scaled, feature_names, idx=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Integrated Gradients (Simplified)\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand gradient-based attribution\n",
    "- Compute feature sensitivity\n",
    "- Compare with SHAP and LIME\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Integrated Gradients:** Path integration method that attributes prediction to input features by accumulating gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Simplified gradient-based attribution\n",
    "def gradient_based_attribution(model, X_test, feature_names, idx=0):\n",
    "    \"\"\"\n",
    "    Simplified gradient-based feature attribution\n",
    "    Using logistic regression coefficients as a proxy\n",
    "    \"\"\"\n",
    "    print(\"Gradient-Based Attribution (Simplified)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train a logistic regression as interpretable proxy\n",
    "    lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get coefficients (gradients)\n",
    "    gradients = lr_model.coef_[0]\n",
    "    \n",
    "    # Attribution = gradient √ó input\n",
    "    patient_features = X_test[idx]\n",
    "    attribution = gradients * patient_features\n",
    "    \n",
    "    # Create DataFrame\n",
    "    grad_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Gradient': gradients,\n",
    "        'Feature Value': patient_features,\n",
    "        'Attribution': attribution\n",
    "    }).sort_values('Attribution', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"\\nGradient-Based Feature Attribution:\")\n",
    "    display(grad_df)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    colors = ['red' if x > 0 else 'blue' for x in grad_df['Attribution']]\n",
    "    ax.barh(grad_df['Feature'], grad_df['Attribution'], color=colors, alpha=0.7)\n",
    "    ax.set_xlabel('Attribution Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Gradient-Based Attribution', fontsize=14, fontweight='bold')\n",
    "    ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return grad_df\n",
    "\n",
    "grad_attribution = gradient_based_attribution(rf_model, X_test_scaled, feature_names, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: Counterfactual Explanations\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Generate \"what-if\" scenarios\n",
    "- Find minimal changes needed to alter prediction\n",
    "- Provide actionable recommendations\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Counterfactuals:** Answer \"What would need to change for a different outcome?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Generate counterfactual explanation\n",
    "def generate_counterfactual(model, patient_data, scaler, feature_names):\n",
    "    \"\"\"\n",
    "    Generate simple counterfactual: what changes would flip the prediction?\n",
    "    \"\"\"\n",
    "    print(\"Counterfactual Analysis: What-If Scenarios\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Original prediction\n",
    "    patient_scaled = scaler.transform(patient_data.values.reshape(1, -1))\n",
    "    original_pred = model.predict(patient_scaled)[0]\n",
    "    original_proba = model.predict_proba(patient_scaled)[0]\n",
    "    \n",
    "    print(\"\\nOriginal Patient Status:\")\n",
    "    for feature, value in patient_data.items():\n",
    "        print(f\"  {feature:20s}: {value:.2f}\")\n",
    "    print(f\"\\n  Prediction: {'HIGH RISK ‚ö†Ô∏è' if original_pred == 1 else 'Low Risk ‚úì'}\")\n",
    "    print(f\"  High Risk Probability: {original_proba[1]:.3f}\")\n",
    "    \n",
    "    # Generate counterfactuals\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Counterfactual Scenarios:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    counterfactuals = []\n",
    "    \n",
    "    # Scenario 1: Reduce blood pressure\n",
    "    cf1 = patient_data.copy()\n",
    "    cf1['Blood_Pressure'] = 120  # Healthy level\n",
    "    cf1_scaled = scaler.transform(cf1.values.reshape(1, -1))\n",
    "    cf1_pred = model.predict(cf1_scaled)[0]\n",
    "    cf1_proba = model.predict_proba(cf1_scaled)[0][1]\n",
    "    \n",
    "    counterfactuals.append({\n",
    "        'Scenario': 'Lower Blood Pressure to 120',\n",
    "        'Changes': f\"Blood Pressure: {patient_data['Blood_Pressure']:.0f} ‚Üí 120\",\n",
    "        'New Prediction': 'High Risk' if cf1_pred == 1 else 'Low Risk',\n",
    "        'New Probability': cf1_proba,\n",
    "        'Risk Reduction': (original_proba[1] - cf1_proba) * 100\n",
    "    })\n",
    "    \n",
    "    # Scenario 2: Increase exercise\n",
    "    cf2 = patient_data.copy()\n",
    "    cf2['Exercise_Hours'] = 5  # Regular exercise\n",
    "    cf2_scaled = scaler.transform(cf2.values.reshape(1, -1))\n",
    "    cf2_pred = model.predict(cf2_scaled)[0]\n",
    "    cf2_proba = model.predict_proba(cf2_scaled)[0][1]\n",
    "    \n",
    "    counterfactuals.append({\n",
    "        'Scenario': 'Exercise 5 hours/week',\n",
    "        'Changes': f\"Exercise: {patient_data['Exercise_Hours']:.1f} ‚Üí 5.0 hours/week\",\n",
    "        'New Prediction': 'High Risk' if cf2_pred == 1 else 'Low Risk',\n",
    "        'New Probability': cf2_proba,\n",
    "        'Risk Reduction': (original_proba[1] - cf2_proba) * 100\n",
    "    })\n",
    "    \n",
    "    # Scenario 3: Combined intervention\n",
    "    cf3 = patient_data.copy()\n",
    "    cf3['Blood_Pressure'] = 120\n",
    "    cf3['Exercise_Hours'] = 5\n",
    "    cf3['BMI'] = max(18, cf3['BMI'] - 3)  # Lose some weight\n",
    "    cf3_scaled = scaler.transform(cf3.values.reshape(1, -1))\n",
    "    cf3_pred = model.predict(cf3_scaled)[0]\n",
    "    cf3_proba = model.predict_proba(cf3_scaled)[0][1]\n",
    "    \n",
    "    counterfactuals.append({\n",
    "        'Scenario': 'Combined: BP + Exercise + Weight',\n",
    "        'Changes': f\"BP‚Üí120, Exercise‚Üí5h, BMI‚Üí{cf3['BMI']:.1f}\",\n",
    "        'New Prediction': 'High Risk' if cf3_pred == 1 else 'Low Risk',\n",
    "        'New Probability': cf3_proba,\n",
    "        'Risk Reduction': (original_proba[1] - cf3_proba) * 100\n",
    "    })\n",
    "    \n",
    "    # Display results\n",
    "    cf_df = pd.DataFrame(counterfactuals)\n",
    "    display(cf_df)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    scenarios = ['Original'] + [cf['Scenario'] for cf in counterfactuals]\n",
    "    probabilities = [original_proba[1]] + [cf['New Probability'] for cf in counterfactuals]\n",
    "    \n",
    "    colors = ['red' if p > 0.5 else 'green' for p in probabilities]\n",
    "    bars = ax.bar(scenarios, probabilities, color=colors, alpha=0.7)\n",
    "    \n",
    "    ax.set_ylabel('High Risk Probability', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Counterfactual Scenarios: Risk Probability Changes', fontsize=14, fontweight='bold')\n",
    "    ax.axhline(y=0.5, color='black', linestyle='--', linewidth=1, label='Decision Threshold')\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{prob:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüéØ Actionable Recommendations:\")\n",
    "    best_scenario = cf_df.loc[cf_df['Risk Reduction'].idxmax()]\n",
    "    print(f\"  Best intervention: {best_scenario['Scenario']}\")\n",
    "    print(f\"  Risk reduction: {best_scenario['Risk Reduction']:.1f}%\")\n",
    "    print(f\"  Changes needed: {best_scenario['Changes']}\")\n",
    "    \n",
    "    return cf_df\n",
    "\n",
    "# Generate counterfactuals for first patient\n",
    "counterfactual_results = generate_counterfactual(\n",
    "    rf_model, patient_info, scaler, feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 7: Model Comparison - Performance vs Interpretability\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Compare model accuracy vs interpretability\n",
    "- Understand the trade-off\n",
    "- Choose appropriate models for clinical use\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Trade-off:** More complex models (higher accuracy) are often less interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Performance vs Interpretability Analysis\n",
    "def performance_interpretability_tradeoff():\n",
    "    \"\"\"\n",
    "    Visualize the trade-off between model performance and interpretability\n",
    "    \"\"\"\n",
    "    print(\"Performance vs. Interpretability Trade-off\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define interpretability scores (subjective, for demonstration)\n",
    "    model_comparison = [\n",
    "        {'Model': 'Logistic Regression', 'Accuracy': results['Logistic Regression']['accuracy'], \n",
    "         'Interpretability': 0.9, 'Complexity': 'Low'},\n",
    "        {'Model': 'Decision Tree', 'Accuracy': results['Decision Tree']['accuracy'], \n",
    "         'Interpretability': 0.85, 'Complexity': 'Low'},\n",
    "        {'Model': 'Random Forest', 'Accuracy': results['Random Forest']['accuracy'], \n",
    "         'Interpretability': 0.5, 'Complexity': 'Medium'},\n",
    "        {'Model': 'Gradient Boosting', 'Accuracy': results['Gradient Boosting']['accuracy'], \n",
    "         'Interpretability': 0.3, 'Complexity': 'High'}\n",
    "    ]\n",
    "    \n",
    "    comparison_df = pd.DataFrame(model_comparison)\n",
    "    \n",
    "    print(\"\\nModel Comparison:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    \n",
    "    colors = {'Low': 'green', 'Medium': 'orange', 'High': 'red'}\n",
    "    \n",
    "    for _, row in comparison_df.iterrows():\n",
    "        ax.scatter(row['Interpretability'], row['Accuracy'], \n",
    "                  s=300, c=colors[row['Complexity']], \n",
    "                  alpha=0.6, edgecolors='black', linewidth=2)\n",
    "        ax.annotate(row['Model'], \n",
    "                   (row['Interpretability'], row['Accuracy']),\n",
    "                   xytext=(10, 10), textcoords='offset points',\n",
    "                   fontsize=11, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Ideal zone\n",
    "    ideal_x = [0.7, 1.0, 1.0, 0.7, 0.7]\n",
    "    ideal_y = [0.7, 0.7, 1.0, 1.0, 0.7]\n",
    "    ax.fill(ideal_x, ideal_y, alpha=0.2, color='green', label='Ideal Zone')\n",
    "    \n",
    "    ax.set_xlabel('Interpretability', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Model Performance vs. Interpretability Trade-off', \n",
    "                fontsize=15, fontweight='bold')\n",
    "    ax.set_xlim([0, 1.05])\n",
    "    ax.set_ylim([0.5, 1.0])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='green', alpha=0.6, label='Low Complexity'),\n",
    "        Patch(facecolor='orange', alpha=0.6, label='Medium Complexity'),\n",
    "        Patch(facecolor='red', alpha=0.6, label='High Complexity'),\n",
    "        Patch(facecolor='green', alpha=0.2, label='Ideal Zone')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower left', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Key Insights:\")\n",
    "    print(\"  ‚úì Logistic Regression: Most interpretable, good baseline\")\n",
    "    print(\"  ‚úì Decision Tree: Visual interpretability, moderate accuracy\")\n",
    "    print(\"  ‚ö†Ô∏è Random Forest: Better accuracy, requires XAI tools (SHAP/LIME)\")\n",
    "    print(\"  ‚ö†Ô∏è Gradient Boosting: Highest accuracy, needs extensive explanation\")\n",
    "    print(\"\\nüí° For high-stakes medical decisions: Choose simpler models or use XAI!\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "model_tradeoff = performance_interpretability_tradeoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **Feature Importance (Attention)**: Which features the model focuses on\n",
    "2. **SHAP Values**: Game-theoretic feature contributions for each prediction\n",
    "3. **LIME**: Local model-agnostic explanations\n",
    "4. **Gradient Attribution**: How input changes affect predictions\n",
    "5. **Counterfactual Explanations**: What-if scenarios for actionable insights\n",
    "6. **Performance vs. Interpretability**: Understanding the trade-off\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "‚úÖ **Multiple XAI methods exist** - Choose based on your needs and model type  \n",
    "‚úÖ **SHAP is comprehensive** - Theoretically grounded, works for most models  \n",
    "‚úÖ **LIME is fast and flexible** - Good for quick local explanations  \n",
    "‚úÖ **Counterfactuals are actionable** - Help clinicians understand interventions  \n",
    "‚úÖ **Trade-offs matter** - Balance accuracy with interpretability based on stakes  \n",
    "\n",
    "### Clinical Application:\n",
    "\n",
    "üè• **For Physicians:**\n",
    "- Explanations validate clinical intuition\n",
    "- Identify which patient factors drive risk\n",
    "- Support shared decision-making with patients\n",
    "\n",
    "üë• **For Patients:**\n",
    "- Understand their risk factors\n",
    "- See what they can change (modifiable factors)\n",
    "- Build trust in AI-assisted healthcare\n",
    "\n",
    "üìã **For Regulators:**\n",
    "- Audit model decisions\n",
    "- Ensure fairness and safety\n",
    "- Document decision-making process\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Apply XAI to your own medical datasets\n",
    "2. Explore Captum for deep learning models\n",
    "3. Try attention visualization for medical images\n",
    "4. Implement audit trails for clinical deployment\n",
    "5. Study regulatory requirements (FDA, EU AI Act)\n",
    "\n",
    "### Resources:\n",
    "\n",
    "üìö **Libraries:**\n",
    "- SHAP: https://github.com/slundberg/shap\n",
    "- LIME: https://github.com/marcotcr/lime\n",
    "- Captum: https://captum.ai/\n",
    "- InterpretML: https://interpret.ml/\n",
    "\n",
    "üìñ **Papers:**\n",
    "- \"A Unified Approach to Interpreting Model Predictions\" (SHAP)\n",
    "- \"Why Should I Trust You?\" (LIME)\n",
    "- \"Axiomatic Attribution for Deep Networks\" (Integrated Gradients)\n",
    "\n",
    "---\n",
    "\n",
    "**üéì Congratulations! You've completed the Explainable Medical AI hands-on practice!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
